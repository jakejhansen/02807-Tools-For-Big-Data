{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 1, 1]\n",
      "[1, 0, 0]\n",
      "[1, 0, 1]\n",
      "[1, 1, 0]\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def get_bitstrings(N,arr = []):\n",
    "    if len(arr) == N:\n",
    "        yield arr\n",
    "    else:\n",
    "        yield from get_bitstrings(N, arr + [0])\n",
    "        yield from get_bitstrings(N, arr + [1])\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    gen = get_bitstrings(3)\n",
    "    for item in gen:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Load data into file\n",
    "with open('pizza-train.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "\n",
    "# Take the request_text and put it into a list of strings\n",
    "request_texts = []\n",
    "for entry in data:\n",
    "    request_texts.append(entry[\"request_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take each string, remove non alphabetic charecters and split it into words in a list\n",
    "# the result with be a list of lists, containing the words of each request as entries\n",
    "request_texts_list = []\n",
    "for i in range(len(request_texts)):\n",
    "    request_texts_list.append(list(filter(str.isalpha, request_texts[i].lower().split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the lists of lists into a single list, so we can find all the unique words using set\n",
    "flat_list = [item for sublist in request_texts_list for item in sublist]\n",
    "words = list(set(flat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "i = 0\n",
    "for w in words:\n",
    "    d[w] = i\n",
    "    i += 1\n",
    "\n",
    "bag_of_words = []\n",
    "for i in range(len(request_texts_list)):\n",
    "    res = [0]*len(words)\n",
    "    for w in request_texts_list[i]:\n",
    "        res[d[w]] += 1\n",
    "    bag_of_words.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words (M): 9471\n",
      "Total texts (N): 4040\n",
      "Number of elements in matrix:38262840\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words (M): {}\".format(len(bag_of_words[0])))\n",
    "print(\"Total texts (N): {}\".format(len(bag_of_words)))\n",
    "print(\"Number of elements in matrix:{}\".format(len(bag_of_words[0])*len(bag_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed list:\n",
      "['a', 'able', 'all', 'am', 'and', 'another', 'appreciated', 'are', 'ask', 'be', 'blessing', 'can', 'children', 'coming', 'exahusted', 'family', 'feed', 'find', 'food', 'for', 'give', 'greatly', 'hard', 'has', 'have', 'heart', 'help', 'hi', 'hit', 'i', 'in', 'is', 'it', 'just', 'know', 'make', 'means', 'military', 'my', 'need', 'night', 'of', 'our', 'really', 'so', 'that', 'through', 'times', 'to', 'u', 'we', 'whatever', 'your']\n",
      "\n",
      " True list, sorted:\n",
      "['a', 'able', 'all', 'am', 'and', 'another', 'appreciated', 'are', 'ask', 'be', 'blessing', 'can', 'children', 'coming', 'exahusted', 'family', 'feed', 'find', 'food', 'for', 'give', 'greatly', 'hard', 'has', 'have', 'heart', 'help', 'hi', 'hit', 'i', 'in', 'is', 'it', 'just', 'know', 'make', 'means', 'military', 'my', 'need', 'night', 'of', 'our', 'really', 'so', 'that', 'through', 'times', 'to', 'u', 'we', 'whatever', 'your']\n",
      "\n",
      " Lists are equal?: True\n"
     ]
    }
   ],
   "source": [
    "# Sanity test, reconstruct first request from the bag_of_words matrix and see that it matches the actual request\n",
    "idx = [i for i, x in enumerate(bag_of_words[0]) if x >= 1]\n",
    "test = [words[i] for i in idx]\n",
    "print(\"Reconstructed list:\")\n",
    "print(sorted(test))\n",
    "print(\"\\n True list, sorted:\")\n",
    "print(sorted(set(request_texts_list[0])))\n",
    "print(\"\\n Lists are equal?: {}\".format(sorted(test) == sorted(set(request_texts_list[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': 'Male', 'age': 28, 'name': 'Thomas'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "person = {}\n",
    "person['name'] = 'Thomas'\n",
    "person[\"age\"] = 28\n",
    "person['Gender'] = 'Male'\n",
    "d[person['name']] = person\n",
    "\n",
    "person2 = {}\n",
    "person2['name'] = 'Anders'\n",
    "person2[\"age\"] = 27\n",
    "person2['Gender'] = 'Male'\n",
    "d[person2['name']] = person2\n",
    "\n",
    "def find_oldest_person(dic):\n",
    "    first_key = list(dic.keys())[0]\n",
    "    oldest = dic.get(first_key)\n",
    "    for person in dic:\n",
    "        if dic[person]['age'] > oldest['age']:\n",
    "            oldest = person\n",
    "\n",
    "    return oldest\n",
    "\n",
    "find_oldest_person(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Construct a bag of words representation (takes some time, double for-loop)\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "bag_of_words = []\n",
    "for i in range(len(request_texts)):\n",
    "    res = []\n",
    "    for w in words:\n",
    "        res.append(request_texts[i].count(w))\n",
    "    bag_of_words.append(res)\n",
    "    \n",
    "print(time.time() - t)\n",
    "\n",
    "# Alternative way, finding the index in the word list instead of counting.\n",
    "import time\n",
    "t = time.time()\n",
    "bag_of_words = []\n",
    "for i in range(len(request_texts)):\n",
    "    res = [0] * len(words)\n",
    "    for word in request_texts_list[i]:\n",
    "        res[words.index(word)] += 1\n",
    "    bag_of_words.append(res)\n",
    "print(time.time() - t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Idea**: Make dictionary of dictionaries, and use it as a database of employees. Each employee has a name, salery, months are the company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular substrings of \"ACAAGATGCCATTGTCCCCCGGCCTCCTG\" with N = 3:\n",
      "CCC: 3\n",
      "GCC: 2\n",
      "CCT: 2\n",
      "Most popular substrings of \"ACAAGATGCCATTGTCCCCCGGCCTCCTG\" with N = 2:\n",
      "CC: 7\n",
      "TG: 3\n",
      "AT: 2\n"
     ]
    }
   ],
   "source": [
    "s = \"ACAAGATGCCATTGTCCCCCGGCCTCCTG\"\n",
    "\n",
    "def most_freq(s,N):\n",
    "    # Make dictionary to store sub-strings as key and number of times\n",
    "    # the occur as values\n",
    "    d = {}\n",
    "    \n",
    "    # Look at N charecters of the string and run through it\n",
    "    # from left to right\n",
    "    for i in range(len(s)-N+1):\n",
    "        # Extract sub-string\n",
    "        sub = s[i:i+N]\n",
    "        if sub in d:\n",
    "            # If the substring is already in the dictionary, \n",
    "            # increment the value by 1\n",
    "            d[s[i:i+N]] += 1\n",
    "        else:\n",
    "            # Else add the substring to the dictionary and give it\n",
    "            # a value of 1\n",
    "            d[s[i:i+N]] = 1\n",
    "            \n",
    "    # sort the dictionary by the number of occourences\n",
    "    most_freq = sorted(d, key=d.get, reverse=True)\n",
    "    \n",
    "    # Print the top3 values, use min to be sure that it doesn't fail\n",
    "    # if there are only 0, 1 or 2 substrings in the string. \n",
    "    for i in range(min(len(most_freq), 3)):\n",
    "        print(\"{}: {}\".format(most_freq[i], d[most_freq[i]]))\n",
    "        \n",
    "# Test outputs on the given string:\n",
    "\n",
    "print(\"Most popular substrings of \\\"{}\\\" with N = 3:\".format(s))\n",
    "most_freq(s,3)\n",
    "print(\"Most popular substrings of \\\"{}\\\" with N = 2:\".format(s))\n",
    "most_freq(s,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
